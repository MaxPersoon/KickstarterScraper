{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['goal'] *= data['fx_rate']\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['raised'] = data['pledged'] * data['fx_rate']\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['country'] = data['country'].apply(lambda entry: getCountry(entry))\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['projectID'] = data['profile'].apply(lambda entry: getProjectID(entry))\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['successful'] = (data['raised'] >= data['goal'])\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['disaster'] = (data['raised'] == 0)\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['duration'] = ((data['deadline'] - data['launched_at']) / 3600 / 24)\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['creator_gender'] = data[['country', 'creator']].apply(lambda entry: getGender(entry), axis=1)\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['U.S.'] = (data['country'] == \"usa\")\n",
      "C:\\Users\\Perso\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['url'] = data['urls'].apply(lambda entry: getUrl(entry))\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_10012/1691395917.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     99\u001B[0m         \u001B[0mscrapeDate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscrapeDates\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 101\u001B[1;33m     \u001B[0mallData\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mallData\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcleanData\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Kickstarter Data\\\\\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscrapeDate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    102\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[0mallData\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    486\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    487\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 488\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    489\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1045\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m         \u001B[0mnrows\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"nrows\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1047\u001B[1;33m         \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1048\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1049\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    222\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlow_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 224\u001B[1;33m                 \u001B[0mchunks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_low_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    225\u001B[0m                 \u001B[1;31m# destructive to chunks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_concatenate_chunks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchunks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mParserError\u001B[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import gender_guesser.detector as gg\n",
    "\n",
    "\n",
    "def cleanData(data, scrapeDate):\n",
    "    # Remove ongoing projects (at the time of scraping)\n",
    "    scrapeDateUNIX = time.mktime(datetime(scrapeDate[0], scrapeDate[1], scrapeDate[2], 12, 0, 0).timetuple())  # conversion to UNIX timestamp\n",
    "    data = data[(data['deadline'] < scrapeDateUNIX)]\n",
    "\n",
    "    # Modifying columns\n",
    "    data['goal'] *= data['fx_rate']\n",
    "    data['raised'] = data['pledged'] * data['fx_rate']\n",
    "    data['country'] = data['country'].apply(lambda entry: getCountry(entry))\n",
    "\n",
    "    # Creating new columns\n",
    "    data['projectID'] = data['profile'].apply(lambda entry: getProjectID(entry))\n",
    "    data['successful'] = (data['raised'] >= data['goal'])\n",
    "    data['disaster'] = (data['raised'] == 0)\n",
    "    data['duration'] = ((data['deadline'] - data['launched_at']) / 3600 / 24)\n",
    "    data['creator_gender'] = data[['country', 'creator']].apply(lambda entry: getGender(entry), axis=1)\n",
    "    data['U.S.'] = (data['country'] == \"usa\")\n",
    "    data['url'] = data['urls'].apply(lambda entry: getUrl(entry))\n",
    "\n",
    "    # Remove entries with an 'unknown' or 'andy' gender\n",
    "    data = data[(data['creator_gender'].isin(['male', 'female', 'mostly_male', 'mostly_female']))]\n",
    "\n",
    "    # Modifying columns, again\n",
    "    data = data.set_index('projectID')\n",
    "    data['successful'] = data['successful'].replace({True: 1, False: 0})\n",
    "    data['disaster'] = data['disaster'].replace({True: 1, False: 0})\n",
    "    data['creator_gender'] = data['creator_gender'].replace({'male': 1, 'female': 0, 'mostly_male': 1, 'mostly_female': 0})\n",
    "    data['U.S.'] = data['U.S.'].replace({True: 1, False: 0})\n",
    "\n",
    "    # Misc\n",
    "    data = data.rename(columns={\"backers_count\": \"no_backers\"})\n",
    "    data = data[['successful', 'disaster', 'goal', 'raised', 'no_backers', 'duration', 'creator_gender', 'U.S.', 'url']]\n",
    "    return data\n",
    "\n",
    "def getCountry(countryCode):\n",
    "    if countryCode in countries.keys():\n",
    "        return countries.get(countryCode)\n",
    "    else:\n",
    "        return \"other_countries\"\n",
    "\n",
    "def getProjectID(entry):\n",
    "    projectID = entry.split(\",\")[1]\n",
    "    projectID = int(projectID.split(\":\")[1])\n",
    "    return projectID\n",
    "\n",
    "def getGender(entry):\n",
    "    fullName = entry['creator'].split(\",\")[1]\n",
    "    fullName = fullName.split(\":\")[1]\n",
    "    fullName = fullName.replace(\"\\\"\", \"\")\n",
    "    firstName = fullName.split(\" \")[0]\n",
    "    gender = genderDetector.get_gender(firstName, entry['country'])\n",
    "    return gender\n",
    "\n",
    "def getUrl(entry):\n",
    "    url = entry.split(\",\")[0]\n",
    "    url = url.split(\"\\\"\")[5]\n",
    "    url = url.split(\"?\")[0]\n",
    "    return url\n",
    "\n",
    "def getDateFromFileName(fileName):\n",
    "    split = fileName.split('-')\n",
    "    del split[2]\n",
    "    return '-'.join(split)\n",
    "\n",
    "scrapeDates = [\n",
    "    [2019, 6, 13], [2019, 7, 18], [2019, 8, 15], [2019, 9, 12], [2019, 10, 17], [2019, 11, 14], [2019, 12, 12],\n",
    "    [2020, 1, 16], [2020, 2, 13], [2020, 3, 12], [2020, 4, 16], [2020, 5, 14], [2020, 6, 18], [2020, 7, 16], [2020, 8, 13], [2020, 9, 17], [2020, 10, 15], [2020, 11, 12], [2020, 12, 17],\n",
    "    [2021, 1, 14], [2021, 2, 11], [2021, 3, 18], [2021, 4, 15], [2021, 5, 17], [2021, 6, 17], [2021, 7, 15], [2021, 8, 12], [2021, 9, 16], [2021, 10, 15], [2021, 11, 19], [2021, 12, 14],\n",
    "    [2022, 1, 20], [2022, 2, 10], [2022, 3, 24], [2022, 4, 21], [2022, 5, 19], [2022, 6, 9], [2022, 7, 14], [2022, 8, 11]\n",
    "]\n",
    "countries = {\n",
    "    \"GB\": \"great_britain\", \"IE\": \"ireland\", \"US\": \"usa\", \"IT\": \"italy\", \"MT\": \"malta\", \"PT\": \"portugal\", \"ES\": \"spain\", \"FR\": \"france\",\n",
    "    \"BE\": \"belgium\", \"LU\": \"luxembourg\", \"NL\": \"the_netherlands\", \"DE\": \"germany\", \"AT\": \"austria\", \"CH\": \"swiss\", \"IS\": \"iceland\",\n",
    "    \"DK\": \"denmark\", \"NO\": \"norway\", \"SE\": \"sweden\", \"FI\": \"finland\", \"EE\": \"estonia\", \"LV\": \"latvia\", \"LT\": \"lithuania\", \"PL\": \"poland\",\n",
    "    \"CZ\": \"czech_republic\", \"SK\": \"slovakia\", \"HU\": \"hungary\", \"RO\": \"romania\", \"BG\": \"bulgaria\", \"BA\": \"bosniaand\", \"HR\": \"croatia\",\n",
    "    \"XK\": \"kosovo\", \"MK\": \"macedonia\", \"ME\": \"montenegro\", \"RS\": \"serbia\", \"SI\": \"slovenia\", \"AL\": \"albania\", \"GR\": \"greece\", \"RU\": \"russia\",\n",
    "    \"BY\": \"belarus\", \"MD\": \"moldova\", \"UA\": \"ukraine\", \"AM\": \"armenia\", \"AZ\": \"azerbaijan\", \"GE\": \"georgia\", \"KZ\": \"the_stans\", \"KG\": \"the_stans\",\n",
    "    \"TJ\": \"the_stans\", \"TM\": \"the_stans\", \"UZ\": \"the_stans\", \"TR\": \"turkey\", \"SA\": \"arabia\", \"IL\": \"israel\", \"CN\": \"china\", \"IN\": \"india\",\n",
    "    \"JP\": \"japan\", \"KR\": \"korea\", \"VN\": \"vietnam\"\n",
    "}\n",
    "files = os.listdir(\"Kickstarter Data\")\n",
    "genderDetector = gg.Detector()\n",
    "\n",
    "allData = cleanData(pd.read_csv(\"Kickstarter Data\\\\\" + files[0]), scrapeDates[0])\n",
    "\n",
    "previousDate = getDateFromFileName(files.pop(0))\n",
    "scrapeDate = scrapeDates.pop(0)\n",
    "for file in files:\n",
    "    date = getDateFromFileName(file)\n",
    "    if date != previousDate:\n",
    "        previousDate = date\n",
    "        scrapeDate = scrapeDates.pop(0)\n",
    "\n",
    "    allData = pd.concat([allData, cleanData(pd.read_csv(\"Kickstarter Data\\\\\" + file), scrapeDate)])\n",
    "\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "           backers_count      category  \\\nprojectID                                \n2246288              740           art   \n2944476                3  film & video   \n1985482             1752  film & video   \n2309240              185    publishing   \n3398789              111           art   \n...                  ...           ...   \n4097                   2           art   \n1764554                1        crafts   \n3465487              263         music   \n2029134                3          food   \n3529120               31    publishing   \n\n                                         creator_profile_url  disaster  \\\nprojectID                                                                \n2246288      https://www.kickstarter.com/profile/skullgarden         0   \n2944476       https://www.kickstarter.com/profile/2031793373         0   \n1985482      https://www.kickstarter.com/profile/madoverlord         0   \n2309240        https://www.kickstarter.com/profile/672576444         0   \n3398789          https://www.kickstarter.com/profile/pabkins         0   \n...                                                      ...       ...   \n4097           https://www.kickstarter.com/profile/343865871         0   \n1764554       https://www.kickstarter.com/profile/1689407442         0   \n3465487        https://www.kickstarter.com/profile/423088081         0   \n2029134       https://www.kickstarter.com/profile/1888439791         0   \n3529120    https://www.kickstarter.com/profile/pkcommissions         0   \n\n            duration     goal     margin  \\\nprojectID                                  \n2246288    31.003067   3400.0   15159.00   \n2944476    58.959757   4000.0   -3920.00   \n1985482    29.958333  30000.0  105589.94   \n2309240    30.000000   4000.0     652.00   \n3398789    30.003738   4900.0     730.00   \n...              ...      ...        ...   \n4097       84.242627   1000.0    -940.00   \n1764554    30.000000   1000.0    -990.00   \n3465487    30.000000  17500.0     991.00   \n2029134    27.171227   3300.0   -3230.00   \n3529120    31.624421    880.0     275.00   \n\n                                                 project_url     raised  \\\nprojectID                                                                 \n2246288    https://www.kickstarter.com/projects/skullgard...   18559.00   \n2944476    https://www.kickstarter.com/projects/203179337...      80.00   \n1985482    https://www.kickstarter.com/projects/madoverlo...  135589.94   \n2309240    https://www.kickstarter.com/projects/672576444...    4652.00   \n3398789    https://www.kickstarter.com/projects/pabkins/g...    5630.00   \n...                                                      ...        ...   \n4097       https://www.kickstarter.com/projects/343865871...      60.00   \n1764554    https://www.kickstarter.com/projects/168940744...      10.00   \n3465487    https://www.kickstarter.com/projects/423088081...   18491.00   \n2029134    https://www.kickstarter.com/projects/188843979...      70.00   \n3529120    https://www.kickstarter.com/projects/pkcommiss...    1155.00   \n\n           success  \nprojectID           \n2246288          1  \n2944476          0  \n1985482          1  \n2309240          1  \n3398789          1  \n...            ...  \n4097             0  \n1764554          0  \n3465487          1  \n2029134          0  \n3529120          1  \n\n[2492 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>backers_count</th>\n      <th>category</th>\n      <th>creator_profile_url</th>\n      <th>disaster</th>\n      <th>duration</th>\n      <th>goal</th>\n      <th>margin</th>\n      <th>project_url</th>\n      <th>raised</th>\n      <th>success</th>\n    </tr>\n    <tr>\n      <th>projectID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2246288</th>\n      <td>740</td>\n      <td>art</td>\n      <td>https://www.kickstarter.com/profile/skullgarden</td>\n      <td>0</td>\n      <td>31.003067</td>\n      <td>3400.0</td>\n      <td>15159.00</td>\n      <td>https://www.kickstarter.com/projects/skullgard...</td>\n      <td>18559.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2944476</th>\n      <td>3</td>\n      <td>film &amp; video</td>\n      <td>https://www.kickstarter.com/profile/2031793373</td>\n      <td>0</td>\n      <td>58.959757</td>\n      <td>4000.0</td>\n      <td>-3920.00</td>\n      <td>https://www.kickstarter.com/projects/203179337...</td>\n      <td>80.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1985482</th>\n      <td>1752</td>\n      <td>film &amp; video</td>\n      <td>https://www.kickstarter.com/profile/madoverlord</td>\n      <td>0</td>\n      <td>29.958333</td>\n      <td>30000.0</td>\n      <td>105589.94</td>\n      <td>https://www.kickstarter.com/projects/madoverlo...</td>\n      <td>135589.94</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2309240</th>\n      <td>185</td>\n      <td>publishing</td>\n      <td>https://www.kickstarter.com/profile/672576444</td>\n      <td>0</td>\n      <td>30.000000</td>\n      <td>4000.0</td>\n      <td>652.00</td>\n      <td>https://www.kickstarter.com/projects/672576444...</td>\n      <td>4652.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3398789</th>\n      <td>111</td>\n      <td>art</td>\n      <td>https://www.kickstarter.com/profile/pabkins</td>\n      <td>0</td>\n      <td>30.003738</td>\n      <td>4900.0</td>\n      <td>730.00</td>\n      <td>https://www.kickstarter.com/projects/pabkins/g...</td>\n      <td>5630.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4097</th>\n      <td>2</td>\n      <td>art</td>\n      <td>https://www.kickstarter.com/profile/343865871</td>\n      <td>0</td>\n      <td>84.242627</td>\n      <td>1000.0</td>\n      <td>-940.00</td>\n      <td>https://www.kickstarter.com/projects/343865871...</td>\n      <td>60.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1764554</th>\n      <td>1</td>\n      <td>crafts</td>\n      <td>https://www.kickstarter.com/profile/1689407442</td>\n      <td>0</td>\n      <td>30.000000</td>\n      <td>1000.0</td>\n      <td>-990.00</td>\n      <td>https://www.kickstarter.com/projects/168940744...</td>\n      <td>10.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3465487</th>\n      <td>263</td>\n      <td>music</td>\n      <td>https://www.kickstarter.com/profile/423088081</td>\n      <td>0</td>\n      <td>30.000000</td>\n      <td>17500.0</td>\n      <td>991.00</td>\n      <td>https://www.kickstarter.com/projects/423088081...</td>\n      <td>18491.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2029134</th>\n      <td>3</td>\n      <td>food</td>\n      <td>https://www.kickstarter.com/profile/1888439791</td>\n      <td>0</td>\n      <td>27.171227</td>\n      <td>3300.0</td>\n      <td>-3230.00</td>\n      <td>https://www.kickstarter.com/projects/188843979...</td>\n      <td>70.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3529120</th>\n      <td>31</td>\n      <td>publishing</td>\n      <td>https://www.kickstarter.com/profile/pkcommissions</td>\n      <td>0</td>\n      <td>31.624421</td>\n      <td>880.0</td>\n      <td>275.00</td>\n      <td>https://www.kickstarter.com/projects/pkcommiss...</td>\n      <td>1155.00</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2492 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def cleanData(data):\n",
    "    # Select relevant columns\n",
    "    data = data[['backers_count', 'category', 'country', 'creator', 'deadline', 'fx_rate', 'goal', 'launched_at', 'photo', 'pledged', 'profile', 'state', 'urls']]\n",
    "\n",
    "    # Filtering\n",
    "    data = data[data['country'] == \"US\"]\n",
    "    data = data[data['state'].isin(['successful', 'failed'])]\n",
    "\n",
    "    # Modifying existing columns\n",
    "    data['category'] = data['category'].apply(lambda entry: getCategoryName(entry))\n",
    "    data['creator'] = data['creator'].apply(lambda entry: getCreatorProfileURL(entry))\n",
    "    data['goal'] *= data['fx_rate']\n",
    "    data['pledged'] *= data['fx_rate']\n",
    "    data['profile'] = data['profile'].apply(lambda entry: getProjectID(entry))\n",
    "    data['state'] = data['state'].replace({'successful': 1, 'failed': 0})\n",
    "    data['urls'] = data['urls'].apply(lambda entry: getProjectURL(entry))\n",
    "\n",
    "    # Creating new columns\n",
    "    data['disaster'] = (data['pledged'] == 0)\n",
    "    data['disaster'] = data['disaster'].replace({True: 1, False: 0})\n",
    "    data['duration'] = (data['deadline'] - data['launched_at']) / 3600 / 24\n",
    "    data['margin'] = (data['pledged'] - data['goal'])\n",
    "\n",
    "    # Misc\n",
    "    data = data.rename(columns={\"creator\": \"creator_profile_url\", \"pledged\": \"raised\", \"profile\": \"projectID\", \"state\": \"success\", \"urls\": \"project_url\"})\n",
    "    data = data.set_index('projectID')\n",
    "    data = data[['backers_count', 'category', 'creator_profile_url', 'disaster', 'duration', 'goal', 'margin', 'project_url', 'raised', 'success']]\n",
    "\n",
    "    return data\n",
    "\n",
    "def getCreatorProfileURL(entry):\n",
    "    tmp = entry.split(\",\")\n",
    "    tmp = tmp[len(tmp) - 2]\n",
    "    tmp = tmp.split(\"{\")[2]\n",
    "    creatorProfileURL = tmp.split(\"\\\"\")[3]\n",
    "    return creatorProfileURL\n",
    "\n",
    "def getCategoryName(entry):\n",
    "    tmp = entry.split(\",\")[2]\n",
    "    tmp = tmp.split(\":\")[1]\n",
    "    tmp = tmp.split(\"/\")[0]\n",
    "    categoryName = tmp.replace(\"\\\"\", \"\")\n",
    "    return categoryName\n",
    "\n",
    "def getProjectID(entry):\n",
    "    tmp = entry.split(\",\")[1]\n",
    "    projectID = int(tmp.split(\":\")[1])\n",
    "    return projectID\n",
    "\n",
    "def getProjectURL(entry):\n",
    "    tmp = entry.split(\",\")[0]\n",
    "    tmp = tmp.split(\"\\\"\")[5]\n",
    "    projectURL = tmp.split(\"?\")[0]\n",
    "    return projectURL\n",
    "\n",
    "allData = cleanData(pd.read_csv(\"Kickstarter Data\\\\2019-06-01.csv\"))\n",
    "allData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}